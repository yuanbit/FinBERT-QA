{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bertQA-pairwise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1bb2268913b44a7ca811a308b8dc9236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e3091cfd3e1480983ff1ba5e7f70b91",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f360134e2a514bf6b6c1dacef6fd4a0d",
              "IPY_MODEL_0e19c0645a9a4f3bb3e953980821dd46"
            ]
          }
        },
        "9e3091cfd3e1480983ff1ba5e7f70b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f360134e2a514bf6b6c1dacef6fd4a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cba374ffc00b4e2f8c34c8b988204ec0",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46709f33dfbe4fc2bec388a9c1619cd7"
          }
        },
        "0e19c0645a9a4f3bb3e953980821dd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87f5e767b3b54560b5d3920ef2843d23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 4.98MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60b8caba72af4c54a77391a24fa4c015"
          }
        },
        "cba374ffc00b4e2f8c34c8b988204ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46709f33dfbe4fc2bec388a9c1619cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87f5e767b3b54560b5d3920ef2843d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60b8caba72af4c54a77391a24fa4c015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "daa87693fa4942e28dded9539bce9cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dcd141be563740299757d679e4ff6605",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a272e3d02a9244b7891547e0abf0ccbe",
              "IPY_MODEL_cfc6d527f5d44787af910e72cd0c4239"
            ]
          }
        },
        "dcd141be563740299757d679e4ff6605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a272e3d02a9244b7891547e0abf0ccbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2927d664cf340a6843c914fe7f460b3",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3103bc68186c4872973756fb7adb6f20"
          }
        },
        "cfc6d527f5d44787af910e72cd0c4239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b986e0c076b40129cf2cc5e1c250955",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 15.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42ea22706bbc4b52a7aacd98f23ad005"
          }
        },
        "b2927d664cf340a6843c914fe7f460b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3103bc68186c4872973756fb7adb6f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b986e0c076b40129cf2cc5e1c250955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42ea22706bbc4b52a7aacd98f23ad005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c69210ec1c3a432795e7e4cc896d012d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed3628a3c686468cbf1b9c82da102564",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e774d932f50a49049f1a46f5de3cbbf9",
              "IPY_MODEL_c8f9775c135847e3bf70161b4c8b84aa"
            ]
          }
        },
        "ed3628a3c686468cbf1b9c82da102564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e774d932f50a49049f1a46f5de3cbbf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d840d1904f80470fbac71da05c48242c",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30281eb729b64c6aa0027379c8d57872"
          }
        },
        "c8f9775c135847e3bf70161b4c8b84aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38ce12e9b5b543a9b65b8bdea05c3b3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:08&lt;00:00, 50.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6766014143bb4fc893cfad85b655e91b"
          }
        },
        "d840d1904f80470fbac71da05c48242c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30281eb729b64c6aa0027379c8d57872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38ce12e9b5b543a9b65b8bdea05c3b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6766014143bb4fc893cfad85b655e91b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySXHdHsEUxNd",
        "colab_type": "code",
        "outputId": "9d338ca2-e5ce-4468-d47a-8fc91ebd3a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hWS0v0sx7J",
        "colab_type": "code",
        "outputId": "79cdd698-a133-438e-8976-b43aa50acbed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "import pickle\n",
        "import random\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from itertools import islice\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "# Setting device on GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(1234)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Tesla P100-PCIE-16GB\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc8577480d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX3dEiY-MzxU",
        "colab_type": "code",
        "outputId": "c916e40e-ae0c-464c-def6-0d16e83809d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.18)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhPBExB2bjG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"drive/My Drive/FiQA/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBGukeI_cCPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from evaluate import *\n",
        "from utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iCcUYUvb6-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary - key: qid, value: list of positive docid\n",
        "train_qid_rel = load_pickle(path + \"new-data/qid_rel_train.pickle\")\n",
        "test_qid_rel = load_pickle(path + \"new-data/qid_rel_test.pickle\")\n",
        "valid_qid_rel = load_pickle(path + \"new-data/qid_rel_valid.pickle\")\n",
        "\n",
        "# List of lists:\n",
        "# Each element is a list containing [qid, positive docid, negative docid]\n",
        "# train_set = load_pickle(path + 'new-data/data_50/train_set_50.pickle')\n",
        "# valid_set = load_pickle(path + 'new-data/data_50/valid_set_50.pickle')\n",
        "# train_set = load_pickle(path + 'new-data/data_25/train_set_25.pickle')\n",
        "# valid_set = load_pickle(path + 'new-data/data_25/valid_set_25.pickle')\n",
        "train_set = load_pickle(path + 'new-data/data_10/train_set_10.pickle')\n",
        "valid_set = load_pickle(path + 'new-data/data_10/valid_set_10.pickle')\n",
        "# train_set = load_pickle(path + 'new-data/train_set.pickle')\n",
        "# valid_set = load_pickle(path + 'new-data/valid_set.pickle')\n",
        "\n",
        "# List of lists:\n",
        "# Each element is a list contraining [qid, list of pos docid, list of candidate docid]\n",
        "# Contains candidates with all pos docids\n",
        "test_set = load_pickle(path + 'new-data/data_50/test_set_50.pickle')\n",
        "# Contains candidates retrieved by BM25\n",
        "# May be missing pos docids in candidates\n",
        "test_set_full = load_pickle(path + 'new-data/data_50/test_set_full_50.pickle')\n",
        "\n",
        "# Dictionary mapping docid and qid to raw text\n",
        "docid_to_text = load_pickle(path + 'new-data/docid_to_text.pickle')\n",
        "qid_to_text = load_pickle(path + 'new-data/qid_to_text.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9_sM2Lrb794",
        "colab_type": "code",
        "outputId": "fed10e49-0a03-4ecf-a2d7-98f4bc53fd2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(\"Number of training samples: {}\".format(len(train_set)))\n",
        "print(\"Number of validation samples: {}\".format(len(valid_set)))\n",
        "print(\"Number of test samples: {}\".format(len(test_set)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 56810\n",
            "Number of validation samples: 6320\n",
            "Number of test samples: 333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRSvaM8BEvH8",
        "colab_type": "code",
        "outputId": "fded6f65-44af-47eb-bfd4-5ce68e7f583e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Example of the training set [qid, pos docid, neg docid]\n",
        "print(train_set[:10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 18850, 214003], [0, 18850, 473658], [0, 18850, 468016], [0, 18850, 319793], [0, 18850, 318321], [0, 18850, 490176], [0, 18850, 573077], [0, 18850, 523540], [0, 18850, 257835], [0, 18850, 499286]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6npVgMDNewIW",
        "colab_type": "code",
        "outputId": "b35fc2ab-11c8-4fab-bb0f-05de4306f253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "1bb2268913b44a7ca811a308b8dc9236",
            "9e3091cfd3e1480983ff1ba5e7f70b91",
            "f360134e2a514bf6b6c1dacef6fd4a0d",
            "0e19c0645a9a4f3bb3e953980821dd46",
            "cba374ffc00b4e2f8c34c8b988204ec0",
            "46709f33dfbe4fc2bec388a9c1619cd7",
            "87f5e767b3b54560b5d3920ef2843d23",
            "60b8caba72af4c54a77391a24fa4c015"
          ]
        }
      },
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bb2268913b44a7ca811a308b8dc9236",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB4xGQLQwSXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input(questions, answers, max_seq_len):\n",
        "    \"\"\"\n",
        "    Returns input objects for training:\n",
        "        input_ids: List of lists\n",
        "                Each element contains a list of padded/clipped numericalized\n",
        "                tokens of the sequences including [CLS] and [SEP] tokens\n",
        "                e.g. [[101, 2054, 2003, 102, 2449, 1029, 102], ...]\n",
        "        token_type_ids: List of lists\n",
        "                Each element contains a list of segment token indices to \n",
        "                indicate first and second portions of the inputs. \n",
        "                0 corresponds to a question token, 1 corresponds an answer token\n",
        "                e.g. [[0, 0, 0, 0, 1, 1, 1], ...]\n",
        "        att_masks: List of lists\n",
        "                Each element contains a list of mask values\n",
        "                Mask to avoid performing attention on padding token indices. \n",
        "                1 for tokens that are NOT MASKED, 0 for MASKED tokens.\n",
        "                e.g. [[1, 1, 1, 1, 1, 1, 1], ...]\n",
        "    -----------------\n",
        "    questions: List of strings\n",
        "            Each element contains a question string\n",
        "    answers: List of strings\n",
        "            Each element contains an asnwer string\n",
        "    max_seq_len: int\n",
        "            Maximum sequence length\n",
        "    \"\"\"\n",
        "    input_ids = []\n",
        "    token_type_ids = []\n",
        "    att_masks = []\n",
        "\n",
        "    for i in tqdm(range(len(questions))):\n",
        "        a = questions[i]\n",
        "        b = answers[i]\n",
        "\n",
        "        # Tokenize the questions and answers, apply padding, and trim the vectors\n",
        "        # to the max_seq_len\n",
        "        encoded_seq = tokenizer.encode_plus(a, b, \n",
        "                                            max_length=max_seq_len, \n",
        "                                            pad_to_max_length=True, \n",
        "                                            return_token_type_ids=True,\n",
        "                                            return_attention_mask = True)\n",
        "\n",
        "        input_id = encoded_seq['input_ids']\n",
        "        token_type_id = encoded_seq['token_type_ids']\n",
        "        att_mask = encoded_seq['attention_mask']\n",
        "\n",
        "        assert len(input_id) == max_seq_len, \"Input id dimension incorrect!\"\n",
        "        assert len(token_type_id) == max_seq_len, \"Token type id dimension incorrect!\"\n",
        "        assert len(att_mask) == max_seq_len, \"Attention mask dimension incorrect!\"\n",
        "\n",
        "        input_ids.append(input_id)\n",
        "        token_type_ids.append(token_type_id)\n",
        "        att_masks.append(att_mask)\n",
        "\n",
        "    return input_ids, token_type_ids, att_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_kGUNI4XK5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    # Get the column with the higher probability\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x5arM3DfYyTO"
      },
      "source": [
        "## **Pairwise**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1C8XAC3Yuj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pairwise_sequence_df(dataset):\n",
        "    \"\"\"\n",
        "    Converts training and validation data into a df with relevancy labels\n",
        "    and map the qid and docid to text.\n",
        "    \n",
        "    Returns data_df: df with columns qid, pos docid,\n",
        "            neg docid, pos label, neg_label, question (text), \n",
        "            pos answer (text), neg answer (text)\n",
        "    ---------------\n",
        "    dataset: train or validation set in the form of list of lists\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(dataset)\n",
        "    df = df.rename(columns={0: 'qid', 1: 'pos_id', 2:'neg_id'})\n",
        "    df['pos_label'] = df.apply(lambda x: 1, axis=1)\n",
        "    df['neg_label'] = df.apply(lambda x: 0, axis=1)\n",
        "\n",
        "    df['question'] = df['qid'].apply(lambda x: qid_to_text[x])\n",
        "    df['pos_ans'] = df['pos_id'].apply(lambda x: docid_to_text[x])\n",
        "    df['neg_ans'] = df['neg_id'].apply(lambda x: docid_to_text[x])\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYRQH1J2Zzxt",
        "colab_type": "code",
        "outputId": "ac6cc66d-d6d5-4faf-cd44-55a7615324e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "trainset = get_pairwise_sequence_df(train_set)\n",
        "train_questions = trainset.question.values\n",
        "train_pos_answers = trainset.pos_ans.values\n",
        "train_neg_answers = trainset.neg_ans.values\n",
        "\n",
        "train_pos_labels = trainset.pos_label.values\n",
        "train_neg_labels = trainset.neg_label.values\n",
        "\n",
        "train_pos_input, train_pos_type_id, train_pos_att_mask = get_input(train_questions, train_pos_answers, 256)\n",
        "train_neg_input, train_neg_type_id, train_neg_att_mask = get_input(train_questions, train_neg_answers, 256)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 56810/56810 [04:17<00:00, 220.78it/s]\n",
            "100%|██████████| 56810/56810 [05:37<00:00, 168.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DsejCaRZ9dO",
        "colab_type": "code",
        "outputId": "2c769fcc-c849-4a4a-96ad-7420d3eb67b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "validset = get_pairwise_sequence_df(valid_set)\n",
        "valid_questions = validset.question.values\n",
        "valid_pos_answers = validset.pos_ans.values\n",
        "valid_neg_answers = validset.neg_ans.values\n",
        "\n",
        "valid_pos_labels = validset.pos_label.values\n",
        "valid_neg_labels = validset.neg_label.values\n",
        "\n",
        "valid_pos_input, valid_pos_type_id, valid_pos_att_mask = get_input(valid_questions, valid_pos_answers, 256)\n",
        "valid_neg_input, valid_neg_type_id, valid_neg_att_mask = get_input(valid_questions, valid_neg_answers, 256)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6320/6320 [00:29<00:00, 216.00it/s]\n",
            "100%|██████████| 6320/6320 [00:28<00:00, 218.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHGawog0Z461",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save_pickle(path+'/data-bert/train_pos_labels_10.pickle', train_pos_labels)\n",
        "# save_pickle(path+'/data-bert/train_neg_labels_10.pickle', train_neg_labels)\n",
        "# save_pickle(path+'/data-bert/valid_pos_labels_10.pickle', valid_pos_labels)\n",
        "# save_pickle(path+'/data-bert/valid_neg_labels_10.pickle', valid_neg_labels)\n",
        "\n",
        "# save_pickle(path+'/data-bert/train_pos_input_256_10.pickle', train_pos_input)\n",
        "# save_pickle(path+'/data-bert/train_neg_input_256_10.pickle', train_neg_input)\n",
        "# save_pickle(path+'/data-bert/valid_pos_input_256_10.pickle', valid_pos_input)\n",
        "# save_pickle(path+'/data-bert/valid_neg_input_256_10.pickle', valid_neg_input)\n",
        "\n",
        "# save_pickle(path+'/data-bert/train_pos_type_id_256_10.pickle', train_pos_type_id)\n",
        "# save_pickle(path+'/data-bert/train_neg_type_id_256_10.pickle', train_neg_type_id)\n",
        "# save_pickle(path+'/data-bert/valid_pos_type_id_256_10.pickle', valid_pos_type_id)\n",
        "# save_pickle(path+'/data-bert/valid_neg_type_id_256_10.pickle', valid_neg_type_id)\n",
        "\n",
        "# save_pickle(path+'/data-bert/train_pos_mask_256_10.pickle', train_pos_att_mask)\n",
        "# save_pickle(path+'/data-bert/train_neg_mask_256_10.pickle', train_neg_att_mask)\n",
        "# save_pickle(path+'/data-bert/valid_pos_mask_256_10.pickle', valid_pos_att_mask)\n",
        "# save_pickle(path+'/data-bert/valid_neg_mask_256_10.pickle', valid_neg_att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdFPxvp-ahTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pos_labels = load_pickle(path+'/data-bert/train_pos_labels_10.pickle')\n",
        "train_neg_labels = load_pickle(path+'/data-bert/train_neg_labels_10.pickle')\n",
        "valid_pos_labels = load_pickle(path+'/data-bert/valid_pos_labels_10.pickle')\n",
        "valid_neg_labels = load_pickle(path+'/data-bert/valid_neg_labels_10.pickle')\n",
        "\n",
        "train_pos_input = load_pickle(path+'/data-bert/train_pos_input_256_10.pickle')\n",
        "train_neg_input = load_pickle(path+'/data-bert/train_neg_input_256_10.pickle')\n",
        "valid_pos_input = load_pickle(path+'/data-bert/valid_pos_input_256_10.pickle')\n",
        "valid_neg_input = load_pickle(path+'/data-bert/valid_neg_input_256_10.pickle')\n",
        "\n",
        "train_pos_type_id = load_pickle(path+'/data-bert/train_pos_type_id_256_10.pickle')\n",
        "train_neg_type_id = load_pickle(path+'/data-bert/train_neg_type_id_256_10.pickle')\n",
        "valid_pos_type_id = load_pickle(path+'/data-bert/valid_pos_type_id_256_10.pickle')\n",
        "valid_neg_type_id = load_pickle(path+'/data-bert/valid_neg_type_id_256_10.pickle')\n",
        "\n",
        "train_pos_mask = load_pickle(path+'/data-bert/train_pos_mask_256_10.pickle')\n",
        "train_neg_mask = load_pickle(path+'/data-bert/train_neg_mask_256_10.pickle')\n",
        "valid_pos_mask = load_pickle(path+'/data-bert/valid_pos_mask_256_10.pickle')\n",
        "valid_neg_mask = load_pickle(path+'/data-bert/valid_neg_mask_256_10.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEL7jdoecvbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_pos_labels = train_pos_labels[:100]\n",
        "# train_neg_labels = train_neg_labels[:100]\n",
        "# train_pos_input = train_pos_input[:100]\n",
        "# train_neg_input = train_neg_input[:100]\n",
        "# train_pos_type_id = train_pos_type_id[:100]\n",
        "# train_neg_type_id = train_neg_type_id[:100]\n",
        "# train_pos_mask = train_pos_mask[:100]\n",
        "# train_neg_mask = train_neg_mask[:100]\n",
        "\n",
        "# valid_pos_labels = valid_pos_labels[:10]\n",
        "# valid_neg_labels = valid_neg_labels[:10]\n",
        "# valid_pos_input = valid_pos_input[:10]\n",
        "# valid_neg_input = valid_neg_input[:10]\n",
        "# valid_pos_type_id = valid_pos_type_id[:10]\n",
        "# valid_neg_type_id = valid_neg_type_id[:10]\n",
        "# valid_pos_mask = valid_pos_mask[:10]\n",
        "# valid_neg_mask = valid_neg_mask[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6c9oM8jauOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert lists to PyTorch tensors\n",
        "train_pos_inputs = torch.tensor(train_pos_input)\n",
        "train_neg_inputs = torch.tensor(train_neg_input)\n",
        "valid_pos_inputs = torch.tensor(valid_pos_input)\n",
        "valid_neg_inputs = torch.tensor(valid_neg_input)\n",
        "\n",
        "train_pos_labels = torch.tensor(train_pos_labels)\n",
        "train_neg_labels = torch.tensor(train_neg_labels)\n",
        "valid_pos_labels = torch.tensor(valid_pos_labels)\n",
        "valid_neg_labels = torch.tensor(valid_neg_labels)\n",
        "\n",
        "train_pos_type_ids = torch.tensor(train_pos_type_id)\n",
        "train_neg_type_ids = torch.tensor(train_neg_type_id)\n",
        "valid_pos_type_ids = torch.tensor(valid_pos_type_id)\n",
        "valid_neg_type_ids = torch.tensor(valid_neg_type_id)\n",
        "\n",
        "train_pos_masks = torch.tensor(train_pos_mask)\n",
        "train_neg_masks = torch.tensor(train_neg_mask)\n",
        "valid_pos_masks = torch.tensor(valid_pos_mask)\n",
        "valid_neg_masks = torch.tensor(valid_neg_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sBUeEuDau3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create DataLoaders to train the model in batches\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_pos_inputs, train_pos_type_ids, train_pos_masks, train_pos_labels, train_neg_inputs, train_neg_type_ids, train_neg_masks, train_neg_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(valid_pos_inputs, valid_pos_type_ids, valid_pos_masks, valid_pos_labels, valid_neg_inputs, valid_neg_type_ids, valid_neg_masks, valid_neg_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46AZOrGeawlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pairwise_loss(pos_scores, neg_scores):\n",
        "    \"\"\"\n",
        "    Pairwise learning approach introduced in https://arxiv.org/pdf/1905.07588.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    cross_entropy_loss = -torch.log(pos_scores) - torch.log(1 - neg_scores)\n",
        "\n",
        "    margin = 1\n",
        "\n",
        "    hinge_loss = torch.max(torch.tensor(0, dtype=torch.float).to(device), margin - pos_scores + neg_scores)\n",
        "\n",
        "    loss = (0.5 * cross_entropy_loss + 0.5 * hinge_loss)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ofMf9vDazyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_pairwise(model, train_dataloader, optimizer, scheduler):\n",
        "\n",
        "    # Store the average loss after each epoch so we can plot them.\n",
        "    loss_values = []\n",
        "\n",
        "    # Reset the loss and accuracy for each epoch\n",
        "    total_loss = 0\n",
        "    nb_train_steps = 0\n",
        "    train_accuracy = 0\n",
        "\n",
        "    # Set model in training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "        # batch contains eight PyTorch tensors:\n",
        "        pos_input = batch[0].to(device)\n",
        "        pos_type_id = batch[1].to(device)\n",
        "        pos_mask = batch[2].to(device)\n",
        "        pos_labels = batch[3].to(device)\n",
        "\n",
        "        neg_input = batch[4].to(device)\n",
        "        neg_type_id = batch[5].to(device)\n",
        "        neg_mask = batch[6].to(device)\n",
        "        neg_labels = batch[7].to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Compute predictinos for postive and negative QA pairs\n",
        "        pos_outputs = model(pos_input, token_type_ids=pos_type_id, attention_mask=pos_mask, labels=pos_labels)\n",
        "        neg_outputs = model(neg_input, token_type_ids=neg_type_id, attention_mask=neg_mask, labels=neg_labels)\n",
        "\n",
        "        # Get the logits from the model for positive and negative QA pairs\n",
        "        pos_logits = pos_outputs[1]\n",
        "        neg_logits = neg_outputs[1]\n",
        "\n",
        "        # Get the column of the relevant scores and apply activation function\n",
        "        pos_scores = softmax(pos_logits, dim=1)[:,1]\n",
        "        neg_scores = softmax(neg_logits, dim=1)[:,1]\n",
        "        \n",
        "        # Compute pairwise loss and get the mean of each batch\n",
        "        loss = pairwise_loss(pos_scores, neg_scores).mean()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        p_logits = pos_logits.detach().cpu().numpy()\n",
        "        p_labels = pos_labels.to('cpu').numpy()\n",
        "        n_logits = neg_logits.detach().cpu().numpy()\n",
        "        n_labels = neg_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for each batch\n",
        "        tmp_pos_accuracy = flat_accuracy(p_logits, p_labels)\n",
        "        tmp_neg_accuracy = flat_accuracy(n_logits, n_labels)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        train_accuracy += tmp_pos_accuracy\n",
        "        train_accuracy += tmp_neg_accuracy\n",
        "        \n",
        "        # Track the number of batches (2 for pos and neg accuracies)\n",
        "        nb_train_steps += 2\n",
        "\n",
        "        # Accumulate the training loss over all of the batches\n",
        "        total_loss += loss.item()\n",
        "    \n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    # Compute accuracy for each epoch\n",
        "    acc = train_accuracy/nb_train_steps\n",
        "\n",
        "    return avg_train_loss, acc, loss_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wZBD9-BdFEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_pairwise(model, validation_dataloader):\n",
        "\n",
        "    # Set model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    eval_accuracy = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in tqdm(validation_dataloader):\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        pos_input, pos_type_id, pos_mask, pos_labels, neg_input, neg_type_id, neg_mask, neg_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # Compute predictinos for postive and negative QA pairs\n",
        "            pos_outputs = model(pos_input, token_type_ids=pos_type_id, attention_mask=pos_mask, labels=pos_labels)\n",
        "            neg_outputs = model(neg_input, token_type_ids=neg_type_id, attention_mask=neg_mask, labels=neg_labels)\n",
        "\n",
        "            # Get logits\n",
        "            pos_logits = pos_outputs[1]\n",
        "            neg_logits = neg_outputs[1]\n",
        "\n",
        "            # Apply activation function\n",
        "            pos_scores = softmax(pos_logits, dim=1)[:,1]\n",
        "            neg_scores = softmax(neg_logits, dim=1)[:,1]\n",
        "        \n",
        "        loss = pairwise_loss(pos_scores, neg_scores).mean()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        p_logits = pos_logits.detach().cpu().numpy()\n",
        "        p_labels = pos_labels.to('cpu').numpy()\n",
        "        n_logits = neg_logits.detach().cpu().numpy()\n",
        "        n_labels = neg_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_pos_accuracy = flat_accuracy(p_logits, p_labels)\n",
        "        tmp_neg_accuracy = flat_accuracy(n_logits, n_labels)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_pos_accuracy\n",
        "        eval_accuracy += tmp_neg_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 2\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(validation_dataloader)\n",
        "    acc = eval_accuracy/nb_eval_steps\n",
        "\n",
        "    return avg_loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lxFYsHtADVla"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An_zn-HiYolL",
        "colab_type": "code",
        "outputId": "c8c64f5c-45a5-4676-c5a9-e95de7568f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "daa87693fa4942e28dded9539bce9cb5",
            "dcd141be563740299757d679e4ff6605",
            "a272e3d02a9244b7891547e0abf0ccbe",
            "cfc6d527f5d44787af910e72cd0c4239",
            "b2927d664cf340a6843c914fe7f460b3",
            "3103bc68186c4872973756fb7adb6f20",
            "8b986e0c076b40129cf2cc5e1c250955",
            "42ea22706bbc4b52a7aacd98f23ad005",
            "c69210ec1c3a432795e7e4cc896d012d",
            "ed3628a3c686468cbf1b9c82da102564",
            "e774d932f50a49049f1a46f5de3cbbf9",
            "c8f9775c135847e3bf70161b4c8b84aa",
            "d840d1904f80470fbac71da05c48242c",
            "30281eb729b64c6aa0027379c8d57872",
            "38ce12e9b5b543a9b65b8bdea05c3b3a",
            "6766014143bb4fc893cfad85b655e91b"
          ]
        }
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top\n",
        "\n",
        "# model_path = \"/content/drive/My Drive/FiQA/model/fin_model\"\n",
        "# model = BertForSequenceClassification.from_pretrained(model_path, cache_dir=None, num_labels=2)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", cache_dir=None, num_labels=2)\n",
        "# model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", cache_dir=None, num_labels=2)\n",
        "model.to(device)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "daa87693fa4942e28dded9539bce9cb5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c69210ec1c3a432795e7e4cc896d012d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut7wlYPSlZcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-6, eps = 1e-8)\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3lU_QLEl4lY",
        "colab_type": "code",
        "outputId": "010ba388-c4e4-40bb-886d-2f4c127cd0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Lowest validation lost\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # Evaluate training loss\n",
        "    # train_loss, train_acc, loss_values = train(model, train_dataloader, optimizer, scheduler)\n",
        "    train_loss, train_acc, loss_values = train_pairwise(model, train_dataloader, optimizer, scheduler)\n",
        "    # Evaluate validation loss\n",
        "    # valid_loss, valid_acc = validate(model, validation_dataloader)\n",
        "    valid_loss, valid_acc = validate_pairwise(model, validation_dataloader)\n",
        "    \n",
        "    # At each epoch, if the validation loss is the best\n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), path + 'model/' + str(epoch+1)+'_pairwise_10.pt')\n",
        "\n",
        "    print(\"\\n\\n Epoch {}:\".format(epoch+1))\n",
        "    print(\"\\t Train Loss: {} | Train Accuracy: {}%\".format(round(train_loss, 3), round(train_acc*100, 2)))\n",
        "    print(\"\\t Validation Loss: {} | Validation Accuracy: {}%\\n\".format(round(valid_loss, 3), round(valid_acc*100, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 953/3551 [12:45<34:42,  1.25it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KHBg5FXKOYHU"
      },
      "source": [
        "## **Evalulation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCGbsz18-Urm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rank(model, test_set, qid_rel, max_seq_len):\n",
        "    \"\"\"\n",
        "    Returns a dictionary - key: qid, value: list of ranked candidates\n",
        "    -------------------\n",
        "    model - PyTorch model\n",
        "    test_set - List of lists:\n",
        "            Each element is a list contraining \n",
        "            [qid, list of pos docid, list of candidate docid]\n",
        "    qid_rel: Dictionary\n",
        "            key: qid, value: list of relevant answer id\n",
        "    max_seq_len: int\n",
        "            Maximum sequence length\n",
        "    \"\"\"\n",
        "\n",
        "    # Initiate empty dictionary\n",
        "    qid_pred_rank = {}\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # For each element in the test set\n",
        "    for i, seq in enumerate(tqdm(test_set)):\n",
        "        \n",
        "        # question id, list of rel answers, list of candidates\n",
        "        qid, label, cands = seq[0], seq[1], seq[2]\n",
        "\n",
        "        # Map question id to text\n",
        "        q_text = qid_to_text[qid]\n",
        "\n",
        "        # Convert list to numpy array\n",
        "        cands_id = np.array(cands)\n",
        "\n",
        "        # Empty list for the probability scores of relevancy\n",
        "        scores = []\n",
        "\n",
        "        # For each answer in the candidates\n",
        "        for docid in cands:\n",
        "\n",
        "            # Map the docid to text\n",
        "            ans_text = docid_to_text[docid]\n",
        "\n",
        "            # Create inputs for the model\n",
        "            encoded_seq = tokenizer.encode_plus(q_text, ans_text, \n",
        "                                            max_length=max_seq_len, \n",
        "                                            pad_to_max_length=True, \n",
        "                                            return_token_type_ids=True,\n",
        "                                            return_attention_mask = True)\n",
        "\n",
        "            # Numericalized, padded, clipped seq with special tokens\n",
        "            input_ids = torch.tensor([encoded_seq['input_ids']]).to(device)\n",
        "            # Specify question seq and answer seq\n",
        "            token_type_ids = torch.tensor([encoded_seq['token_type_ids']]).to(device)\n",
        "            # Sepecify which position is part of the seq which is padded\n",
        "            att_mask = torch.tensor([encoded_seq['attention_mask']]).to(device)\n",
        "\n",
        "            # Don't calculate gradients\n",
        "            with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions for each QA pair\n",
        "                outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=att_mask)\n",
        "\n",
        "            # Get the predictions\n",
        "            logits = outputs[0]\n",
        "\n",
        "            # Apply activation function\n",
        "            pred = softmax(logits, dim=1)\n",
        "            # pred = torch.sigmoid(logits)\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            pred = pred.detach().cpu().numpy()\n",
        "\n",
        "            # Append relevant scores to list (where label = 1)\n",
        "            scores.append(pred[:,1][0])\n",
        "\n",
        "        print(scores)\n",
        "\n",
        "        # Get the indices of the sorted similarity scores\n",
        "        sorted_index = np.argsort(scores)[::-1]\n",
        "\n",
        "        # Get the list of docid from the sorted indices\n",
        "        ranked_ans = cands_id[sorted_index]\n",
        "\n",
        "        # Dict - key: qid, value: ranked list of docids\n",
        "        qid_pred_rank[qid] = ranked_ans\n",
        "\n",
        "    return qid_pred_rank"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOR-OM-qbb3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toy_test_label = dict(itertools.islice(test_qid_rel.items(), 2))\n",
        "toy_test = test_set[:2]\n",
        "# toy_test = [[14, [398960], [84963, 14255, 398960]],\n",
        "#             [68, [19183], [107584, 562777, 19183]],\n",
        "#             [70, [327002], [107584, 327002, 19183]]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGa0KvT4cbbo",
        "colab_type": "code",
        "outputId": "74e67074-6efa-4fcf-c93b-005a158dfd3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "model.load_state_dict(torch.load(path+'model/1_pairwise_25.pt'))\n",
        "\n",
        "# qid_pred_rank = get_rank(model, test_set, test_qid_rel, max_seq_len=512)\n",
        "qid_pred_rank = get_rank(model, toy_test, toy_test_label, max_seq_len=256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:07<00:07,  7.39s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.9999527, 0.999949, 0.18187124, 0.999884, 0.000103418584, 0.99862635, 0.9999441, 0.99994326, 0.9999306, 0.999944, 0.9999107, 0.011065468, 0.99990654, 0.9999043, 0.9996063, 0.99993455, 0.999925, 0.9999478, 0.9997577, 0.9284304, 0.124180555, 0.9999361, 0.9197168, 0.9999304, 0.999887, 0.99994993, 0.9999486, 0.00038539234, 0.999936, 0.9999198, 0.98532575, 0.9999027, 0.9998845, 0.99889565, 0.99994695, 0.89547914, 0.9347405, 0.99992275, 0.004050158, 0.0004175653, 0.70191604, 0.9997336, 0.61686075, 0.9996581, 0.99994326, 0.992488, 0.9998895, 0.99988997, 0.0010666391, 0.8459604, 0.9999151, 0.9999553, 0.99987435, 0.99994063, 0.9998692, 0.9999106, 0.77538884, 0.99957675, 0.9996093, 0.9997527, 0.99994993, 0.9999403, 0.8784555, 0.99993014, 0.99838126, 0.9999491, 0.9998518, 0.9999471, 0.9999548, 0.999882, 0.99994826, 0.99995434, 0.99989235, 0.7867769, 0.99981743, 0.74969816, 0.9998274, 0.9997148, 0.00039994254, 0.99994624, 0.087119706, 0.9999229, 0.99973744, 0.99985087, 0.9978452, 0.99994147, 0.9999567, 0.99995446, 0.3475442, 0.011162113, 0.99994624, 0.99995387, 0.99993813, 0.99994767, 0.99995327, 0.99994874, 0.00017699118, 0.99989116, 0.016093124, 0.9999008, 0.9999318, 0.00049407786, 0.9999527, 0.9999449, 0.9996556, 0.99983716, 0.99986494, 0.9975672, 0.999941, 0.99005985, 0.18401062, 0.99994326, 0.9980015, 0.9998871, 0.9998574, 0.99993575, 0.9986897, 0.9999249, 0.9999485, 0.9999355, 0.9997359, 0.99984944, 0.9998853, 0.99994767, 0.027540471, 0.9999496, 0.9999428, 0.0062411474, 0.99810624, 0.9999138, 0.99985135, 0.9999485, 0.9944001, 0.9902857, 0.9999536, 0.9999492, 0.9993875, 0.99985325, 0.99992776, 0.9998654, 0.9999423, 0.99989057, 0.9999386, 0.015173371, 0.999948, 0.99982893, 0.17032662, 0.99995434, 0.99993205, 0.0018434654, 0.999895, 0.9994753, 0.99990904, 0.9999176, 0.999912, 0.9999566, 0.9999424, 0.9998024, 0.99776256, 0.99987614, 0.8275018, 0.0009889285, 0.99995875, 0.009319318, 0.00028031893, 0.9999293, 0.9999342, 0.9999312, 0.99992895, 0.99993265, 0.9996897, 0.99992347, 0.99995065, 0.9998603, 0.3786432, 0.9993813, 0.25336707, 0.9998099, 0.014688242, 0.9985942, 0.9999542, 0.9999542, 0.9999472, 0.022485012, 0.00012552446, 0.03372591, 0.9999417, 0.99994004, 0.9999496, 0.99898344, 0.99995446, 0.9998878, 0.99994624, 0.9990663, 0.9999398, 0.8716433, 0.9999192, 0.9994031, 0.9999435, 0.9972427, 0.99993575, 0.013907222, 0.999949, 0.99994445, 0.9999393, 0.9999417, 0.98887306, 0.0022712164, 0.9999548, 0.99956363, 0.9998759, 0.99740976, 0.9999056, 0.9999441, 0.99992514, 0.99994004, 0.0041667507, 0.9999466, 0.99989283, 0.9998449, 0.9999473, 0.9999479, 0.9999361, 0.99994373, 0.999951, 0.9999492, 0.999928, 0.9999114, 0.9993136, 0.9999167, 0.99994147, 0.9999398, 0.9999479, 0.00053685583, 0.99995315, 0.99992406, 0.99993765, 0.99994373, 0.9999522, 0.02693599, 0.9999324, 0.99994695, 0.99995327, 0.6568741, 0.9999479, 0.99993694, 0.9999291, 0.99978, 0.9999385, 0.99988484, 0.9998721, 0.6906214, 0.18763976, 0.99995494, 0.99993515, 0.9846363, 0.29567248, 0.9999591, 0.99960643, 0.00019369536, 0.99994755, 0.00022218659, 0.00017739246, 0.99995637, 0.9995105, 0.4746182, 0.9999169, 0.99993384, 0.99992144, 0.99993694, 0.9673961, 0.9999119, 0.9999467, 0.951224, 0.5392592, 0.9999517, 0.42235917, 0.99952865, 0.20740855, 0.9999107, 0.9967524, 0.9999422, 0.89208066, 0.9993143, 0.9999354, 0.99988127, 0.99985313, 0.9998691, 0.9998375, 0.9999554, 0.99993074, 0.0066825054, 0.999918, 0.9572586, 0.999861, 0.9999349, 0.9997602, 0.99993336, 0.99993813, 0.99991465, 0.9999131, 0.9993851, 0.024105452, 0.99974746, 0.9998603, 0.5560292, 0.999954, 0.9999461, 0.99995625, 0.9999536, 0.9999547, 0.9999367, 0.99995184, 0.9999585, 0.99587005, 0.30289543, 0.9999498, 0.9995384, 0.9997918, 0.9998723, 0.99380255, 0.99962723, 0.9999447, 0.005616155, 0.99982077, 0.07931997, 0.9998528, 0.99989283, 0.9999558, 0.9999473, 0.9999546, 0.9999571, 0.999954, 0.99763, 0.9991522, 0.99994516, 0.99991536, 0.9999467, 0.9997539, 0.99988747, 0.9999492, 0.9999466, 0.18748252, 0.9999337, 0.99994195, 0.9911942, 0.9999306, 0.99995613, 0.9999131, 0.9994217, 0.9999372, 0.9993955, 0.99994457, 0.99987924, 0.9976736, 0.000103669576, 0.99989116, 0.9999354, 0.999944, 0.99994004, 0.999941, 0.99994326, 0.9999536, 0.99986565, 0.99994516, 0.99993634, 0.9999474, 0.007200234, 0.99989676, 0.9715897, 0.9999536, 0.99994826, 0.99994683, 0.9998982, 0.9999306, 0.999918, 0.5604524, 0.9998903, 0.99984777, 0.9990293, 0.99995327, 0.9999566, 0.99961615, 0.9999529, 0.9999527, 0.5317129, 0.99992764, 0.9998934, 0.9999528, 0.004281145, 0.99995136, 0.9999063, 0.032023247, 0.9995689, 0.9999559, 0.9998319, 0.99993396, 0.99995244, 0.9999509, 0.999819, 0.9994667, 0.99994373, 0.9999566, 0.99993753, 0.9996741, 0.0009729735, 0.99994826, 0.99994195, 0.87127954, 0.9999554, 0.9998698, 0.9999274, 0.008103746, 0.9999225, 0.0023392676, 0.999956, 0.9950093, 0.9995968, 0.99985564, 0.18005766, 0.99995387, 0.00021571707, 0.9998616, 0.99995327, 0.03440732, 0.9999453, 0.004972663, 0.00013354399, 0.99993026, 0.9999472, 0.99994326, 0.9998454, 0.9999212, 0.89780915, 0.99995065, 0.99744177, 0.99994504, 0.010077396, 0.9998449, 0.014185263, 0.9999517, 0.99942845, 0.9998652, 0.9999254, 0.72560793, 0.99962544, 0.99986136, 0.45438176, 0.0017595548, 0.27680638, 0.9999517, 0.9998981, 0.9999356, 0.9997354, 0.0013328773, 0.99993575, 0.9999416, 0.99995315, 0.9999403, 0.9999523, 0.9999449, 0.99995375, 0.99992764, 0.9999577, 0.99994063, 0.999749, 0.05377649, 0.99992406, 0.0014594522, 0.93989396, 0.98956245, 0.999881, 0.8421778, 0.9999479, 0.9999459, 0.9992349, 0.9999336, 0.99994516, 0.99953306, 0.999948, 0.7785077, 0.99995136, 0.99994504, 0.99993134, 0.99994874, 0.35641298, 0.99995136, 0.9999293, 0.99698585, 0.9999496, 0.9999535, 0.9998964, 0.99969745, 0.040776797, 0.99957055, 0.99747914, 0.9999075, 0.99995494, 0.9937273, 0.99993443]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 2/2 [00:15<00:00,  7.49s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.9999287, 0.0072370716, 0.99994373, 0.9999317, 0.9999299, 0.99995506, 0.99957365, 0.9999552, 0.00057716575, 0.9998795, 0.9999534, 0.99996006, 0.9999405, 0.9999261, 0.99993515, 0.7964893, 0.99969685, 0.9999058, 0.9999336, 0.8458747, 0.9999441, 0.9999472, 0.99995685, 0.99995244, 0.9999547, 0.99401265, 0.9999547, 0.99992085, 0.9999304, 0.9998442, 0.99995935, 0.99789006, 0.99994314, 0.999928, 0.9999423, 0.99995923, 0.99995387, 0.9999374, 0.9999492, 0.9999448, 0.999943, 0.99992156, 0.99994683, 0.9996908, 0.99995124, 0.9999485, 0.9999329, 0.00013012807, 0.99995685, 0.0009288644, 0.99994457, 0.9998565, 0.022961553, 0.99992335, 0.99994254, 0.9998714, 0.9999542, 0.9999484, 0.9996592, 0.99994934, 0.9999589, 0.99993706, 0.9998497, 0.99993575, 0.9999453, 0.99995613, 0.9999505, 0.9998099, 0.011141944, 0.99994516, 0.9999552, 0.9999478, 0.99994814, 0.9999567, 0.99995184, 0.99995375, 0.9999583, 0.00016959306, 0.9999527, 0.9999472, 0.9999584, 0.9999287, 0.99984765, 0.9999304, 0.00031214024, 0.9999368, 0.9997166, 0.999962, 0.9999609, 0.9964545, 0.9999554, 0.999954, 0.9999422, 0.99995005, 0.9998473, 0.9999571, 0.9999081, 0.9999417, 0.9999341, 0.9991947, 0.99995506, 0.99995875, 0.00054983335, 0.99945396, 0.99920964, 0.99994147, 0.99995744, 0.99995697, 0.9695939, 0.99993753, 0.99981076, 0.9999602, 0.9999548, 0.99989724, 0.9999529, 0.9999455, 0.99995446, 0.9999478, 0.9999577, 0.99995327, 0.99969625, 0.99995875, 0.9999503, 0.99995494, 0.99986744, 0.99988616, 0.9999577, 0.99995434, 0.99995136, 0.9999541, 0.99988925, 0.9999541, 0.9999331, 0.9999571, 0.9999423, 0.99995315, 0.99995065, 0.6186225, 0.9999492, 0.99993825, 0.9999366, 0.00050550397, 0.9999498, 0.99995613, 0.99994874, 0.9999552, 0.9999348, 0.9999484, 0.999918, 0.9999404, 0.9999368, 0.9999428, 0.99995744, 0.9999509, 0.99995816, 0.99836737, 0.9999342, 0.99994195, 0.4308989, 0.9999449, 0.9999455, 0.99995196, 0.0044896863, 0.9999498, 0.9998845, 0.9999509, 0.99994695, 0.99995995, 0.99983335, 0.99995124, 0.99994385, 0.99929214, 0.99632144, 0.99995303, 0.999788, 0.9999056, 0.99995553, 0.99994993, 0.9999553, 0.99995804, 0.99924695, 0.999959, 0.1295024, 0.99995637, 0.99996006, 0.99993455, 0.9959189, 0.99995935, 0.9999249, 0.99995875, 0.9998727, 0.9999466, 0.99995065, 0.9995265, 0.99994266, 0.9999479, 0.99996126, 0.9999496, 0.0943796, 0.999943, 0.02653428, 0.9999347, 0.9999294, 0.0010781545, 0.9954803, 0.99993527, 0.9999559, 0.9999393, 0.9801108, 0.9999511, 0.99995923, 0.9999491, 0.9999101, 0.9998698, 0.99995744, 0.999948, 0.9999591, 0.99995816, 0.99995434, 0.99994946, 0.99995935, 0.9999181, 0.9999465, 0.9999167, 0.9999504, 0.99993885, 0.99933475, 0.99995685, 0.9999484, 0.99993837, 0.9999567, 0.9999577, 0.99994683, 0.999678, 0.9991768, 0.99995637, 0.99995315, 0.9999542, 0.9999498, 0.9998908, 0.999961, 0.9999567, 0.99993694, 0.999948, 0.9999567, 0.9999435, 0.99994075, 0.9965064, 0.9999497, 0.9999399, 0.9999547, 0.9999535, 0.99993336, 0.99994516, 0.999956, 0.99994814, 0.99995077, 0.9999591, 0.99994385, 0.999959, 0.9999491, 0.99991393, 0.99995863, 0.9999566, 0.9999559, 0.9999573, 0.99995434, 0.99995315, 0.99995816, 0.9999542, 0.99992657, 0.99996054, 0.9999423, 0.99994683, 0.9999473, 0.99993265, 0.99995863, 0.9999447, 0.99992645, 0.99989116, 0.9955265, 0.9999441, 0.9998646, 0.9999478, 0.99995065, 0.9999474, 0.9999472, 0.99990034, 0.9997894, 0.9999459, 0.00043835904, 0.9999478, 0.9999552, 0.9997185, 0.9999534, 0.9999316, 0.9999516, 0.9998381, 0.99940956, 0.9999571, 0.99994636, 0.9999567, 0.9999262, 0.9999486, 0.9999455, 0.9999472, 0.99992895, 0.99966204, 0.9999268, 0.99994695, 0.99995136, 0.9999535, 0.99993265, 0.9999578, 0.9999194, 0.99994826, 0.0003821713, 0.99991703, 0.9999577, 0.97868335, 0.9999496, 0.9999138, 0.99995995, 0.00011005535, 0.99994445, 0.9999063, 0.9999447, 0.9998913, 0.9998833, 0.9999435, 0.9999529, 0.999933, 0.99988544, 0.99990547, 0.99986565, 0.9999244, 0.99995136, 0.9999181, 0.9999051, 0.9999591, 0.9999559, 0.99798524, 0.9999534, 0.99990344, 0.010515641, 0.12829946, 0.99992657, 0.9999316, 0.99995613, 0.9999536, 0.99995255, 0.99993753, 0.99995077, 0.99994206, 0.99994826, 0.99996006, 0.9997167, 0.00018124709, 0.994429, 0.99901485, 0.9998078, 0.9999522, 0.9999596, 0.9999424, 0.99954164, 0.9999528, 0.99994504, 0.9999529, 0.99948776, 0.9999409, 0.9998603, 0.99992657, 0.99993026, 0.99995685, 0.9999467, 0.99993837, 0.00022353312, 0.999956, 0.99994624, 0.99992085, 0.99994683, 0.9999467, 0.99985623, 0.99995387, 0.999928, 0.99995744, 0.9999095, 0.99994814, 0.99994206, 0.9999237, 0.99995637, 0.9999578, 0.9999486, 0.99993765, 0.9999554, 0.99995756, 0.999956, 0.99995244, 0.9999567, 0.9999579, 0.99994826, 0.026717095, 0.99996006, 0.9999565, 0.9998155, 0.9999393, 0.99995553, 0.9999596, 0.99995565, 0.9999615, 0.99995375, 0.022707924, 0.99993956, 0.99995863, 0.90225667, 0.9999471, 0.9999584, 0.9672542, 0.99995196, 0.99994874, 0.99995685, 0.99995375, 0.0039665424, 0.9999579, 0.01787288, 0.99994886, 0.99995255, 0.9999329, 0.9999558, 0.99995613, 0.9999542, 0.9999548, 0.9999509, 0.9999571, 0.99995553, 0.9999577, 0.99994767, 0.99995005, 0.9999529, 0.9999399, 0.9999198, 0.99993277, 0.00049240876, 0.9999474, 0.99995863, 0.9999558, 0.99993443, 0.99994946, 0.13373764, 0.9996989, 0.9999366, 0.999933, 0.9999416, 0.9999504, 0.9999467, 0.99995375, 0.99982566, 0.00014307762, 0.998466, 0.99990964, 0.9999497, 0.9999423, 0.9998921, 0.99995494, 0.9999602, 0.99990237, 0.99995875, 0.9999529, 0.9999496, 0.9999502, 0.99959606, 0.9999372, 0.9999546, 0.9999472, 0.99992406, 0.9999554, 0.9996315, 0.99993443, 0.999956, 0.9998332, 0.9999441, 0.9999584, 0.99995923, 0.99995327, 0.99975616, 0.9999417, 0.99994683, 0.9999455, 0.99991775, 0.9999002, 0.0024171418, 0.99991655, 0.9999331, 0.9999535, 0.99995697, 0.99988747, 0.004801053, 0.99995685, 0.99780124, 0.00042007858]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTc2SQVhuv2Q",
        "colab_type": "code",
        "outputId": "56742277-2f16-417b-f5d6-01d1b24ead89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "k = 10\n",
        "\n",
        "num_q = len(test_set)\n",
        "\n",
        "# MRR, average_ndcg, precision, rank_pos = evaluate(qid_pred_rank, test_qid_rel, k)\n",
        "MRR, average_ndcg, precision, rank_pos = evaluate(qid_pred_rank, toy_test_label, k)\n",
        "\n",
        "print(\"\\n\\nAverage nDCG@{} for {} queries: {}\\n\".format(k, num_q, average_ndcg))\n",
        "\n",
        "print(\"MRR@{} for {} queries: {}\\n\".format(k, num_q, MRR))\n",
        "\n",
        "print(\"Average Precision@{}: {}\".format(1, precision))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Average nDCG@10 for 333 queries: 0.4510568402073561\n",
            "\n",
            "MRR@10 for 333 queries: 0.44166666666666665\n",
            "\n",
            "Average Precision@1: 0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcfbXb5eBcX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_pickle(path+'rank/rank_bert_256_full.pickle', qid_pred_rank)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}